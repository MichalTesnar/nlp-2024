{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3706a575deebceab",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Text Classification\n",
    "\n",
    "In this notebook, we will perform text classification to determine if tweets about disasters are about real disasters or not (e.g. fictional disasters). Two feature extraction methods will be shown: tf-idf and word2vec."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-02-22T10:04:22.398738Z",
     "start_time": "2024-02-22T10:04:03.227477Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d709c63b",
   "metadata": {},
   "source": [
    "### Loading Data\n",
    "\n",
    "We will start by loading the data and taking a look at the first few rows. We will then drop the unnecessary columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e876e1f0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-22T10:04:22.419944Z",
     "start_time": "2024-02-22T10:04:22.398542Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2eced90",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-22T10:04:22.445301Z",
     "start_time": "2024-02-22T10:04:22.421090Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   id keyword        location  \\\n0   0  ablaze             NaN   \n1   1  ablaze             NaN   \n2   2  ablaze   New York City   \n3   3  ablaze  Morgantown, WV   \n4   4  ablaze             NaN   \n\n                                                text  target  \n0  Communal violence in Bhainsa, Telangana. \"Ston...       1  \n1  Telangana: Section 144 has been imposed in Bha...       1  \n2  Arsonist sets cars ablaze at dealership https:...       1  \n3  Arsonist sets cars ablaze at dealership https:...       1  \n4  \"Lord Jesus, your love brings freedom and pard...       0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>keyword</th>\n      <th>location</th>\n      <th>text</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>ablaze</td>\n      <td>NaN</td>\n      <td>Communal violence in Bhainsa, Telangana. \"Ston...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>ablaze</td>\n      <td>NaN</td>\n      <td>Telangana: Section 144 has been imposed in Bha...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>ablaze</td>\n      <td>New York City</td>\n      <td>Arsonist sets cars ablaze at dealership https:...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>ablaze</td>\n      <td>Morgantown, WV</td>\n      <td>Arsonist sets cars ablaze at dealership https:...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>ablaze</td>\n      <td>NaN</td>\n      <td>\"Lord Jesus, your love brings freedom and pard...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71c45055",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-22T10:04:22.445796Z",
     "start_time": "2024-02-22T10:04:22.427870Z"
    }
   },
   "outputs": [],
   "source": [
    "# Drop unnecessary columns\n",
    "df = df.drop(columns = [\"id\",\"keyword\",\"location\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84b7b4ff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-22T10:04:22.446450Z",
     "start_time": "2024-02-22T10:04:22.432412Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                                                text  target\n0  Communal violence in Bhainsa, Telangana. \"Ston...       1\n1  Telangana: Section 144 has been imposed in Bha...       1\n2  Arsonist sets cars ablaze at dealership https:...       1\n3  Arsonist sets cars ablaze at dealership https:...       1\n4  \"Lord Jesus, your love brings freedom and pard...       0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Communal violence in Bhainsa, Telangana. \"Ston...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Telangana: Section 144 has been imposed in Bha...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Arsonist sets cars ablaze at dealership https:...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Arsonist sets cars ablaze at dealership https:...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>\"Lord Jesus, your love brings freedom and pard...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf7c655",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "\n",
    "We want to get our text in the right format to improve performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "86eb7622",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-22T12:15:44.887637Z",
     "start_time": "2024-02-22T12:15:44.867152Z"
    }
   },
   "outputs": [],
   "source": [
    "def clean_text(doc):\n",
    "    \"\"\"\n",
    "    This function is used to clean the text data. It performs several operations to preprocess the text data.\n",
    "    \n",
    "    Parameters:\n",
    "    doc (str): The text document that needs to be cleaned.\n",
    "\n",
    "    Returns:\n",
    "    doc (str): The cleaned text document.\n",
    "\n",
    "    The steps involved in the cleaning process are:\n",
    "    1. Convert all characters to lowercase.\n",
    "    2. Replace all punctuation with a space.\n",
    "    3. Split the text into tokens (words) using white space as a delimiter.\n",
    "    4. Remove tokens that are not alphabetic.\n",
    "    5. Filter out English stop words.\n",
    "    6. Filter out short tokens (length <= 1).\n",
    "    7. Join the tokens back into a single string with spaces in between.\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert all characters to lowercase\n",
    "    doc = doc.lower()\n",
    "\n",
    "    # Replace all punctuation with a space\n",
    "    for char in string.punctuation:\n",
    "        doc = doc.replace(char, ' ')\n",
    "\n",
    "    # Split the text into tokens (words) using white space as a delimiter\n",
    "    tokens = doc.split()\n",
    "\n",
    "    # Remove tokens that are not alphabetic\n",
    "    tokens = [word for word in tokens if word.isalpha()]\n",
    "\n",
    "    # Filter out English stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [word for word in tokens if not word in stop_words]\n",
    "\n",
    "    # Filter out short tokens (length <= 1)\n",
    "    tokens = [word for word in tokens if len(word) > 1]\n",
    "\n",
    "    # Join the tokens back into a single string with spaces in between\n",
    "    doc = \" \".join(tokens)\n",
    "\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9ccc1ea4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-22T12:17:12.024272Z",
     "start_time": "2024-02-22T12:17:12.020018Z"
    }
   },
   "outputs": [],
   "source": [
    "def clean_df(df):\n",
    "    \"\"\"\n",
    "    This function is used to clean the text data in a DataFrame. It applies the clean_text function to each text in the DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    df (DataFrame): The DataFrame that contains the text data that needs to be cleaned.\n",
    "\n",
    "    Returns:\n",
    "    cleaned_df (list): A list of cleaned text data.\n",
    "\n",
    "    The steps involved in the cleaning process are:\n",
    "    1. Initialize an empty list, cleaned_df.\n",
    "    2. Iterate over each text in the 'text' column of the DataFrame.\n",
    "    3. Apply the clean_text function to each text.\n",
    "    4. Append the cleaned text to the cleaned_df list.\n",
    "    5. Return the cleaned_df list.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize an empty list, cleaned_df\n",
    "    cleaned_df = []\n",
    "\n",
    "    # Iterate over each text in the 'text' column of the DataFrame\n",
    "    for text in tqdm(df['text']):\n",
    "        # Apply the clean_text function to each text\n",
    "        clean = clean_text(text)\n",
    "\n",
    "        # Append the cleaned text to the cleaned_df list\n",
    "        cleaned_df.append(clean)\n",
    "\n",
    "    # Return the cleaned_df list\n",
    "    return cleaned_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "33e37674",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-22T12:17:12.998381Z",
     "start_time": "2024-02-22T12:17:12.473210Z"
    }
   },
   "outputs": [],
   "source": [
    "cleaned_df = df\n",
    "cleaned_df['text'] = df['text'].apply(lambda x: clean_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "                                                text  target\n0  communal violence bhainsa telangana stones pel...       1\n1  telangana section imposed bhainsa january clas...       1\n2  arsonist sets cars ablaze dealership https co ...       1\n3  arsonist sets cars ablaze dealership https co ...       1\n4  lord jesus love brings freedom pardon fill hol...       0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>communal violence bhainsa telangana stones pel...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>telangana section imposed bhainsa january clas...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>arsonist sets cars ablaze dealership https co ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>arsonist sets cars ablaze dealership https co ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>lord jesus love brings freedom pardon fill hol...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-22T12:17:13.525243Z",
     "start_time": "2024-02-22T12:17:13.517686Z"
    }
   },
   "id": "3fe60d6f",
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "267b952c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-22T12:17:14.511793Z",
     "start_time": "2024-02-22T12:17:14.505849Z"
    }
   },
   "outputs": [],
   "source": [
    "# Splitting the data\n",
    "\n",
    "train_x, test_x, train_y, test_y  = train_test_split(cleaned_df['text'], cleaned_df['target'], test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde92e76",
   "metadata": {},
   "source": [
    "### Tweet classification with tf-idf\n",
    "\n",
    "We will use the tf-idf method to convert the text data into numerical data. Then use a simple Multi-Layered-Perceptron to learn to classify the tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6ec4cf8b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-22T12:17:17.645172Z",
     "start_time": "2024-02-22T12:17:17.639188Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6ea497a4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-22T12:17:20.017399Z",
     "start_time": "2024-02-22T12:17:19.362968Z"
    }
   },
   "outputs": [],
   "source": [
    "# The vectorizer performs the tf_idf calculations for you\n",
    "vectorizer = TfidfVectorizer(use_idf=True, max_features=900)\n",
    "tf_idf_train_text = vectorizer.fit_transform(train_x).toarray()\n",
    "\n",
    "# Make sure only to apply the transormation to test data, \n",
    "# otherwise this is leakage.\n",
    "tf_idf_test_text = vectorizer.transform(test_x).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7fa2b35",
   "metadata": {},
   "source": [
    "We build a simple Multi-Layered-Perceptron to learn to classify the tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d8028743",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-22T12:19:51.101663Z",
     "start_time": "2024-02-22T12:19:50.655690Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "285/285 [==============================] - 0s 575us/step - loss: 0.6659 - accuracy: 0.7806\n"
     ]
    }
   ],
   "source": [
    "# Build the model\n",
    "tf_idf_model = Sequential()\n",
    "tf_idf_model.add(Dense(16, activation='relu', input_shape=(tf_idf_train_text.shape[1],)))\n",
    "tf_idf_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "tf_idf_model.compile(loss='binary_crossentropy', optimizer=optimizers.Adam(learning_rate=0.0001), metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = tf_idf_model.fit(tf_idf_train_text, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "790c1e80",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-22T12:20:00.103272Z",
     "start_time": "2024-02-22T12:19:59.995370Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72/72 [==============================] - 0s 478us/step - loss: 0.6417 - accuracy: 0.8100\n",
      "Test Accuracy: 81.00%\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = tf_idf_model.evaluate(tf_idf_test_text, test_y)\n",
    "print(f'Test Accuracy: {accuracy*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "daa28c0bb6377764"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
